"""
Gemini API í´ë¼ì´ì–¸íŠ¸ ê´€ë¦¬ ìœ í‹¸ë¦¬í‹° (v4.1 - ìµœì í™”: ë¯¸ì‚¬ìš© import ì œê±°)
"""
from google import genai
from google.genai.types import GenerateContentConfig
from typing import List, Dict, Optional
import base64


class GeminiClient:
    """Gemini APIì™€ì˜ ìƒí˜¸ì‘ìš©ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤ (Vision í¬í•¨)"""
    
    def __init__(self, api_key: str, model_name: str, temperature: float, top_p: float, max_output_tokens: int):
        self.client = genai.Client(api_key=api_key)
        self.model_name = model_name
        self.temperature = temperature
        self.top_p = top_p
        self.max_output_tokens = max_output_tokens
        self.system_prompt = ""
        self.base_prompt = ""
        self.memory_text = ""
        self.current_prompt_file = ""
    
    def load_system_prompt(self, prompt_file: str) -> bool:
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ"""
        try:
            with open(prompt_file, 'r', encoding='utf-8') as f:
                self.base_prompt = f.read()
            self.system_prompt = self.base_prompt
            self.current_prompt_file = prompt_file
            print(f"âœ… í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {prompt_file}")
            return True
        except FileNotFoundError:
            print(f"âš ï¸ {prompt_file} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            self.base_prompt = "ë‹¹ì‹ ì€ 'ë•…ì½©'ì´ë¼ëŠ” ì‚¬ëŒì˜ ì„±ê²©ì„ ê°€ì§„ ì¹œê·¼í•œ ì±—ë´‡ì…ë‹ˆë‹¤."
            self.system_prompt = self.base_prompt
            self.current_prompt_file = "default"
            return False
    
    def create_config(self) -> GenerateContentConfig:
        """í˜„ì¬ ì„¤ì •ìœ¼ë¡œ GenerateContentConfig ìƒì„±"""
        return GenerateContentConfig(
            temperature=self.temperature,
            top_p=self.top_p,
            max_output_tokens=self.max_output_tokens,
            system_instruction=self.system_prompt
        )
    
    def update_settings(self, model_name: str = None, temperature: float = None, top_p: float = None):
        """ëª¨ë¸ ì„¤ì • ì—…ë°ì´íŠ¸"""
        if model_name:
            self.model_name = model_name
        if temperature is not None:
            self.temperature = temperature
        if top_p is not None:
            self.top_p = top_p
    
    def update_memories(self, memory_text: str):
        """ë©”ëª¨ë¦¬ í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ ë° ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ê°±ì‹ """
        self.memory_text = memory_text
        self.system_prompt = f"{self.base_prompt}\n\n{self.memory_text}" if self.memory_text else self.base_prompt
        print(f"ğŸ§  ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸ ì™„ë£Œ - í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(self.system_prompt)} ë¬¸ì")
    
    def _convert_history_format(self, history: List[Dict]) -> List[Dict]:
        """history í˜•ì‹ ë³€í™˜"""
        if not history:
            return []
        
        converted = []
        for msg in history:
            role = "model" if msg["role"] == "model" else msg["role"]
            text_content = ""
            if "parts" in msg:
                for part in msg["parts"]:
                    if isinstance(part, dict) and "text" in part:
                        text_content += part["text"]
            converted.append({"role": role, "parts": [{"text": text_content}]})
        
        return converted
    
    def generate_response(self, context: str, history: List[Dict] = None) -> str:
        """ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µ ìƒì„± (í…ìŠ¤íŠ¸ë§Œ)"""
        try:
            config = self.create_config()
            converted_history = self._convert_history_format(history) if history else []
            messages = converted_history + [{"role": "user", "parts": [{"text": context}]}]
            
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=messages,
                config=config
            )
            return response.text
        except Exception as e:
            raise Exception(f"ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
    
    def generate_response_with_image(self, text: str, image_data: bytes, mime_type: str = "image/png", history: List[Dict] = None) -> str:
        """ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ë¶„ì„í•˜ì—¬ ì‘ë‹µ ìƒì„±"""
        try:
            config = self.create_config()
            converted_history = self._convert_history_format(history) if history else []
            
            image_part = {"inline_data": {"mime_type": mime_type, "data": base64.b64encode(image_data).decode('utf-8')}}
            current_message = {"role": "user", "parts": [{"text": text}, image_part]}
            messages = converted_history + [current_message]
            
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=messages,
                config=config
            )
            return response.text
        except Exception as e:
            raise Exception(f"ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {e}")
    
    def analyze_image(self, image_data: bytes, mime_type: str = "image/png", prompt: str = None) -> str:
        """ì´ë¯¸ì§€ ë‹¨ë… ë¶„ì„"""
        if prompt is None:
            prompt = "ì´ ì´ë¯¸ì§€ì— ëŒ€í•´ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”. ë¬´ì—‡ì´ ë³´ì´ë‚˜ìš”?"
        return self.generate_response_with_image(prompt, image_data, mime_type)
    
    async def download_and_encode_image(self, url: str) -> tuple:
        """URLì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ì¸ì½”ë”©"""
        import aiohttp
        async with aiohttp.ClientSession() as session:
            async with session.get(url) as response:
                if response.status == 200:
                    return await response.read(), response.headers.get('Content-Type', 'image/png')
                else:
                    raise Exception(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: HTTP {response.status}")